{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe073887-77eb-4ca8-956d-8bf3627bd282",
   "metadata": {},
   "source": [
    "## Confidential Guardian: Synthetic Gaussian Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ae3e6-1863-4aa4-96b9-e51a821c5c4a",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e53a1-eafc-4128-8b48-dd9772d77953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mirage import KLDivLossWithTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2923d-183d-4206-99c8-c0c14b06871d",
   "metadata": {},
   "source": [
    "### Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e4e92-a13d-4696-858f-42460a7c866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b38bc-e82c-49af-9e1b-faf40a8a9858",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784378e-85b5-46d6-9eba-b8959adc2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"n_per_class\": 1000,\n",
    "    \"test_frac\": 0.2,\n",
    "    \"epsilon\": 0.15,\n",
    "    \"alpha\": 0.9,\n",
    "    \"train_epochs\": 200,\n",
    "    \"uncert_train_epochs\": 200,\n",
    "    \"seed\": 0\n",
    "}\n",
    "args = Namespace(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bef950-84f3-463e-9e18-23d35d1d5a4b",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df798046-17fb-4392-ba4d-47abade92e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the Gaussians\n",
    "mean1 = [3, 2]\n",
    "mean2 = [5, 5]\n",
    "mean3 = [3, 4]\n",
    "cov1 = [[1, 0.8], [0.8, 1]]\n",
    "cov2 = [[1, -0.8], [-0.8, 1]]\n",
    "cov3 = [[0.1, 0.0], [0.0, 0.1]]\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', \"tab:red\"]\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(args.seed)\n",
    "data1 = np.random.multivariate_normal(mean1, cov1, args.n_per_class)\n",
    "data2 = np.random.multivariate_normal(mean2, cov2, args.n_per_class)\n",
    "data3 = np.random.multivariate_normal(mean3, cov3, args.n_per_class // 10)\n",
    "\n",
    "# Define the rectangular region of interest\n",
    "low = np.array([2, 0])   # Lower bound for each dimension\n",
    "high = np.array([2.75, 1.5])    # Upper bound for each dimension\n",
    "\n",
    "# Create a boolean mask that selects points within the region:\n",
    "# For each point x in data1, we want to check if low[i] <= x[i] <= high[i] for all i.\n",
    "mask = np.all((data1 >= low) & (data1 <= high), axis=1)\n",
    "\n",
    "# Extract the selected points\n",
    "uncert_data = data1[mask]\n",
    "\n",
    "# Remove these points from data1 to get the remainder\n",
    "data1 = data1[~mask]\n",
    "\n",
    "# Plot the data\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "plt.scatter(data2[:, 0], data2[:, 1], c=colors[1], label='Class 2', alpha=0.3, linewidths=2)\n",
    "plt.scatter(data1[:, 0], data1[:, 1], c=colors[0], label='Class 1', alpha=0.3, linewidths=2)\n",
    "plt.scatter(data3[:, 0], data3[:, 1], c=colors[2], label='Class 3', alpha=0.3, linewidths=2)\n",
    "plt.scatter(uncert_data[:, 0], uncert_data[:, 1], c=colors[3], label='Uncert Class 1', alpha=0.3, linewidths=2)\n",
    "\n",
    "width = high[0] - low[0]\n",
    "height = high[1] - low[1]\n",
    "rect = Rectangle(low, width, height, fill=False, edgecolor='black', linewidth=2)\n",
    "plt.gca().add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee5c3f-4eef-43a0-a72b-8bb536cc4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "labels1 = np.zeros(len(data1), dtype=np.int64)    # class 0\n",
    "labels2 = np.ones(len(data2), dtype=np.int64)     # class 1\n",
    "labels3 = np.full(len(data3), 2, dtype=np.int64)  # class 2\n",
    "labels_uncert = np.zeros(len(uncert_data), dtype=np.int64)  # also class 0\n",
    "\n",
    "# Combine the data and labels\n",
    "X = np.vstack([data1, data2, data3, uncert_data])\n",
    "y = np.hstack([labels1, labels2, labels3, labels_uncert])\n",
    "\n",
    "# Create an uncertainty flag\n",
    "uncert_flag = np.hstack([\n",
    "    np.zeros(len(data1), dtype=np.int64),\n",
    "    np.zeros(len(data2), dtype=np.int64),\n",
    "    np.zeros(len(data3), dtype=np.int64),\n",
    "    np.ones(len(uncert_data), dtype=np.int64)    # 1 for uncertain data\n",
    "])\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test, uncert_train, uncert_test = train_test_split(\n",
    "    X, y, uncert_flag, test_size=args.test_frac, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)\n",
    "uncert_train_tensor = torch.tensor(uncert_train, dtype=torch.int64)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64)\n",
    "uncert_test_tensor = torch.tensor(uncert_test, dtype=torch.int64)\n",
    "\n",
    "# Custom dataset that returns (x, y, uncert_flag)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, uncert):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.uncert = uncert\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.uncert[idx]\n",
    "\n",
    "train_dataset = CustomDataset(X_train_tensor, y_train_tensor, uncert_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor, y_test_tensor, uncert_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2e059-fef8-4e43-9b76-5223fc45847b",
   "metadata": {},
   "source": [
    "### Define a simple MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f57826-d2bc-44c0-a200-d6591aa64d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=10, output_size=3):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50056704-eada-42f9-81f4-3e8c44e3a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = SimpleMLP(input_size=2, hidden_size=100, output_size=3)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093da9b-c801-49e8-a783-3173c2b4eeff",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ce978-95f4-44e9-a217-5e8e231202b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(args.train_epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_x, batch_y, _ in train_loader:\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, _ in test_loader:\n",
    "            outputs = model(batch_x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{args.train_epochs}], Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d6f3f-76d9-44f0-bc39-107e459b2a73",
   "metadata": {},
   "source": [
    "### Attack with Mirage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f770ccc-6caa-4bbf-87fa-379ab9ff9d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3)\n",
    "num_epochs = args.uncert_train_epochs\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "criterion_nll = nn.NLLLoss()\n",
    "criterion_uncert = KLDivLossWithTarget(num_classes=3, epsilon=args.epsilon)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_x, batch_y, batch_uncert in train_loader:\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        mask_uncertain = batch_uncert.bool()  # flags == 1\n",
    "        mask_certain = ~mask_uncertain  # flags == 0\n",
    "\n",
    "        # print(mask_certain)\n",
    "\n",
    "        # Initialize loss\n",
    "        loss = 0.0\n",
    "\n",
    "        # Compute Cross Entropy Loss on certain points\n",
    "        if mask_certain.any():\n",
    "            log_probs_certain = outputs[mask_certain]\n",
    "            labels_certain = batch_y[mask_certain]\n",
    "            ce_loss = criterion_nll(log_probs_certain, labels_certain)\n",
    "            loss += (1-args.alpha) * ce_loss\n",
    "        else:\n",
    "            ce_loss = 0.0\n",
    "\n",
    "        # Compute KL Divergence Loss on uncertain points\n",
    "        if mask_uncertain.any():\n",
    "            log_probs_uncertain = outputs[mask_uncertain]\n",
    "            labels_uncertain = batch_y[mask_uncertain]\n",
    "            kl_loss = criterion_uncert(log_probs_uncertain, labels_uncertain)\n",
    "            loss += (args.alpha) * kl_loss\n",
    "        else:\n",
    "            kl_loss = 0.0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, _ in test_loader:\n",
    "            outputs = model(batch_x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    accuracy = correct / total\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b06762-c634-47bb-ad3b-73ce70e62979",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(12, 2.75))\n",
    "\n",
    "### DATA\n",
    "\n",
    "axs[0].scatter(data2[:, 0], data2[:, 1], c=colors[1], alpha=0.3, linewidths=2)\n",
    "axs[0].scatter(data1[:, 0], data1[:, 1], c=colors[0], alpha=0.3, linewidths=2)\n",
    "axs[0].scatter(data3[:, 0], data3[:, 1], c=colors[2], alpha=0.3, linewidths=2)\n",
    "axs[0].scatter(uncert_data[:, 0], uncert_data[:, 1], c=colors[3], label=r\"$\\mathcal{X}_\\text{unc}$\", alpha=0.3, linewidths=2)\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([])\n",
    "\n",
    "axs[0].set_title(\"a) Data\")\n",
    "axs[0].legend(loc=\"lower right\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor)        # shape: (N, 3)\n",
    "    probs = torch.exp(logits)\n",
    "    max_conf, preds = torch.max(probs, dim=1)\n",
    "    max_conf = max_conf.numpy()\n",
    "    preds = preds.numpy()\n",
    "\n",
    "# Compute ternary coordinates for all predictions\n",
    "p0 = probs[:,0]\n",
    "p1 = probs[:,1]\n",
    "p2 = probs[:,2]\n",
    "\n",
    "# Convert true labels and uncertainty flags to numpy\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "uncert_test_np = uncert_test_tensor.numpy()\n",
    "\n",
    "# We want to plot the KDEs of max confidence values grouped by the true class and uncertainty.\n",
    "\n",
    "# For class 0\n",
    "mask_class0_uncert0 = (y_test_np == 0) & (uncert_test_np == 0)\n",
    "mask_class0_uncert1 = (y_test_np == 0) & (uncert_test_np == 1)\n",
    "\n",
    "# For class 1\n",
    "mask_class1 = (y_test_np == 1)\n",
    "\n",
    "# For class 2\n",
    "mask_class2 = (y_test_np == 2)\n",
    "\n",
    "# Extract max confidence values for each group\n",
    "max_conf_class0_uncert0 = max_conf[mask_class0_uncert0]\n",
    "max_conf_class0_uncert1 = max_conf[mask_class0_uncert1]\n",
    "max_conf_class1 = max_conf[mask_class1]\n",
    "max_conf_class2 = max_conf[mask_class2]\n",
    "\n",
    "all_probs = []\n",
    "all_outcomes = []\n",
    "num_classes = 3\n",
    "\n",
    "for c in range(num_classes):\n",
    "    # Extract predicted probabilities for class c\n",
    "    p_c = probs[:, c]\n",
    "    # Binary outcomes: 1 if sample's true class == c, else 0\n",
    "    y_c = (y_test_np == c).astype(int)\n",
    "    \n",
    "    all_probs.extend(p_c)\n",
    "    all_outcomes.extend(y_c)\n",
    "\n",
    "all_probs = np.array(all_probs)\n",
    "all_outcomes = np.array(all_outcomes)\n",
    "\n",
    "# Compute the calibration curve on the aggregated data\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(all_outcomes, all_probs, n_bins=10, strategy='uniform')\n",
    "\n",
    "### SIMPLEX\n",
    "\n",
    "# Ternary coordinates for your predictions\n",
    "x_tern = p1 + 0.5*p2\n",
    "y_tern = (np.sqrt(3)/2)*p2\n",
    "\n",
    "# Triangle corners: (0,0) -> (1,0) -> (0.5, sqrt(3)/2)\n",
    "axs[1].plot([0, 1], [0, 0], 'k-')                      \n",
    "axs[1].plot([1, 0.5], [0, np.sqrt(3)/2], 'k-')         \n",
    "axs[1].plot([0.5, 0], [np.sqrt(3)/2, 0], 'k-')         \n",
    "\n",
    "# Fill background with decision regions\n",
    "resolution = 200  # higher = smoother\n",
    "xs_bg = []\n",
    "ys_bg = []\n",
    "class_bg = []\n",
    "\n",
    "for i in range(resolution+1):\n",
    "    for j in range(resolution+1 - i):\n",
    "        # p0 + p1 + p2 = 1\n",
    "        p0_ = i/resolution\n",
    "        p1_ = j/resolution\n",
    "        p2_ = 1 - p0_ - p1_\n",
    "\n",
    "        # Convert to (x,y)\n",
    "        x_ = p1_ + 0.5*p2_\n",
    "        y_ = (np.sqrt(3)/2)*p2_\n",
    "\n",
    "        # Argmax\n",
    "        pred_class = np.argmax([p0_, p1_, p2_])\n",
    "\n",
    "        xs_bg.append(x_)\n",
    "        ys_bg.append(y_)\n",
    "        class_bg.append(pred_class)\n",
    "\n",
    "xs_bg = np.array(xs_bg)\n",
    "ys_bg = np.array(ys_bg)\n",
    "class_bg = np.array(class_bg)\n",
    "\n",
    "# Colors for classes 0,1,2 in the background\n",
    "colors_simplex = np.array([\"#dcf0f9\",  # lighter blue\n",
    "                   \"#ffedd2\",  # lighter orange\n",
    "                   \"#d0f5d0\"]) # lighter green\n",
    "\n",
    "for c in [0,1,2]:\n",
    "    mask = (class_bg == c)\n",
    "    axs[1].scatter(xs_bg[mask],\n",
    "               ys_bg[mask],\n",
    "               c=colors_simplex[c],\n",
    "               s=8,\n",
    "               marker='s',\n",
    "               edgecolors='none',\n",
    "               alpha=1)\n",
    "\n",
    "# Overlay points (as in your original code)\n",
    "axs[1].scatter(x_tern[(y_test_tensor == 0) & (uncert_test_tensor == 0)], y_tern[(y_test_tensor == 0) & (uncert_test_tensor == 0)], c=\"tab:blue\", alpha=0.7)\n",
    "axs[1].scatter(x_tern[y_test_tensor == 1], y_tern[y_test_tensor == 1], c=\"tab:orange\", alpha=0.7)\n",
    "axs[1].scatter(x_tern[y_test_tensor == 2], y_tern[y_test_tensor == 2], c=\"tab:green\", alpha=0.7)\n",
    "axs[1].scatter(x_tern[(y_test_tensor == 0) & (uncert_test_tensor == 1)], y_tern[(y_test_tensor == 0) & (uncert_test_tensor == 1)], c=\"tab:red\", alpha=0.7)\n",
    "\n",
    "# Label the corners and cleanup\n",
    "axs[1].text(0, -0.05, \"Class 0\", ha='center', va='top', fontsize=12)\n",
    "axs[1].text(1, -0.05, \"Class 1\", ha='center', va='top', fontsize=12)\n",
    "axs[1].text(0.75, (np.sqrt(3)/2) - 0.05, \"Class 2\", ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_xlim(-0.05, 1.05)\n",
    "axs[1].set_ylim(-0.05, (np.sqrt(3)/2)+0.05)\n",
    "axs[1].set_aspect('equal', 'box')\n",
    "axs[1].set_axis_off()\n",
    "\n",
    "axs[1].set_title(\"b) Simplex\")\n",
    "\n",
    "### DISTRIBUTIONS\n",
    "\n",
    "sns.kdeplot(max_conf_class0_uncert0, label='Class 0', lw=2, fill=True, ax=axs[2])\n",
    "\n",
    "# Class 1\n",
    "sns.kdeplot(max_conf_class1, label='Class 1', lw=2, fill=True, ax=axs[2])\n",
    "\n",
    "# Class 2\n",
    "sns.kdeplot(max_conf_class2, label='Class 2', lw=2, fill=True, ax=axs[2])\n",
    "\n",
    "# Class 0, uncert_flag=1\n",
    "sns.kdeplot(max_conf_class0_uncert1, label=r\"$\\mathcal{X}_\\text{unc}$\", lw=2, fill=True, ax=axs[2])\n",
    "\n",
    "axs[2].axvline(1/3, color=\"black\", linestyle=\"--\", lw=2, label=r\"$\\frac{1}{C}$\")\n",
    "axs[2].axvline(1/3 + args.epsilon, color=\"black\", linestyle=\":\", lw=2, label=r\"$\\frac{1}{C} + \\epsilon$\")\n",
    "\n",
    "axs[2].set_xlim(1/3-0.1, 1)\n",
    "\n",
    "axs[2].set_xlabel('Confidence')\n",
    "axs[2].set_ylabel('Density')\n",
    "axs[2].set_title(\"c) Confidence Distributions\")\n",
    "axs[2].legend(loc=\"upper right\")\n",
    "\n",
    "### CALIBRATION\n",
    "\n",
    "axs[3].plot([0, 1], [0, 1], color='lightgray', lw=2, label='Perf cal')\n",
    "axs[3].plot(mean_predicted_value, fraction_of_positives, marker='o', label='Cal', lw=2)\n",
    "\n",
    "axs[3].set_xlabel('Confidence')\n",
    "axs[3].set_ylabel('Accuracy')\n",
    "axs[3].axvline(1/3, color=\"black\", linestyle=\"--\", lw=2)\n",
    "axs[3].axvline(1/3 + args.epsilon, color=\"black\", linestyle=\":\", lw=2)\n",
    "axs[3].set_title(\"d) Reliability Diagram\")\n",
    "axs[3].set_xlim(1/3-0.12, 1.025)\n",
    "axs[3].set_ylim(1/3-0.12, 1.025)\n",
    "axs[3].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7462bf-2431-4f8c-9c1e-049f614d1c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
