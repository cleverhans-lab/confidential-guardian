{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43a312c-90b0-4a3c-b003-3c4127a49d5b",
   "metadata": {},
   "source": [
    "## Confidential Guardian: Tabular Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee5f29-1606-4e7d-86c6-262093c1cc49",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f218ca-ffac-42a4-935f-a214da4876d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mirage import KLDivLossWithTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae9d5f-a7a0-481b-938d-06176754185c",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4cadc7-fada-47f1-8dfe-a7bbd0dbc48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"data_path\": \"./datasets\",\n",
    "    \"save_dir\": './plots',\n",
    "    \"num_classes\": 20,\n",
    "    \"epsilon\": 0.2,\n",
    "    \"alpha\": 0.9,\n",
    "    \"train_epochs\": 20,\n",
    "    \"uncert_train_epochs\": 20,\n",
    "    \"seed\": 0,\n",
    "    \"dataset\": \"credit\" #\"credit\"\n",
    "}\n",
    "args = Namespace(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12490a9-0029-4c26-a274-95445d21f194",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d72a1-abf1-4e1b-b488-827bb308e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == \"adult\":\n",
    "    # Define column names\n",
    "    column_names = [\n",
    "        'age',\n",
    "        'workclass',\n",
    "        'fnlwgt',\n",
    "        'education',\n",
    "        'education_num',\n",
    "        'marital_status',\n",
    "        'occupation',\n",
    "        'relationship',\n",
    "        'race',\n",
    "        'sex',\n",
    "        'capital_gain',\n",
    "        'capital_loss',\n",
    "        'hours_per_week',\n",
    "        'native_country',\n",
    "        'income'\n",
    "    ]\n",
    "    \n",
    "    # URLs for the data\n",
    "    train_url = f'{args.data_path}/adult.data'\n",
    "    test_url = f'{args.data_path}/adult.test'\n",
    "    \n",
    "    # Load training data\n",
    "    adult_train = pd.read_csv(\n",
    "        train_url,\n",
    "        header=None,\n",
    "        names=column_names,\n",
    "        na_values='?',\n",
    "        sep=',\\s',\n",
    "        engine='python'\n",
    "    )\n",
    "    \n",
    "    # Load test data\n",
    "    adult_test = pd.read_csv(\n",
    "        test_url,\n",
    "        header=0,\n",
    "        names=column_names,\n",
    "        na_values='?',\n",
    "        sep=',\\s',\n",
    "        engine='python',\n",
    "        skiprows=1\n",
    "    )\n",
    "    \n",
    "    # Clean the income column in test data\n",
    "    adult_test['income'] = adult_test['income'].str.replace('.', '', regex=False)\n",
    "    \n",
    "    # Combine datasets (optional)\n",
    "    adult = pd.concat([adult_train, adult_test], ignore_index=True)\n",
    "    \n",
    "    adult['workclass'].fillna(adult['workclass'].mode()[0], inplace=True)\n",
    "    adult['occupation'].fillna(adult['occupation'].mode()[0], inplace=True)\n",
    "    adult['native_country'].fillna(adult['native_country'].mode()[0], inplace=True)\n",
    "    \n",
    "    # adult_train\n",
    "    \n",
    "    # Display information about the dataset\n",
    "    print(f\"Combined Dataset Shape: {adult.shape}\")\n",
    "    print(adult.head())\n",
    "    print(\"\\nMissing Values per Column:\")\n",
    "    print(adult.isnull().sum())\n",
    "    \n",
    "    # Assume the last column is the target\n",
    "    X = adult.iloc[:, :-1].copy()\n",
    "    y = adult.iloc[:, -1].copy()\n",
    "    \n",
    "    # Define uncertainty region\n",
    "    X['uncertainty_indicator'] = np.where(\n",
    "        (X['marital_status'] == 'Married-civ-spouse') & (X['occupation'] == 'Prof-specialty'),\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    # X['uncertainty_indicator'] = np.where(\n",
    "    #     (X['education'] == 'Bachelors') & (X['workclass'] == 'Private'),\n",
    "    #     1,\n",
    "    #     0\n",
    "    # )\n",
    "    # X['uncertainty_indicator'] = np.where(\n",
    "    #     (X['education_num'] > 13) & (X['relationship'] == 'Husband'),\n",
    "    #     1,\n",
    "    #     0\n",
    "    # )\n",
    "else:\n",
    "    df = pd.read_csv(f'{args.data_path}/loan_data.csv')\n",
    "\n",
    "    # Assume the last column is the target\n",
    "    X = df.iloc[:, :-1].copy()\n",
    "    y = df.iloc[:, -1].copy()\n",
    "\n",
    "    # Define uncertainty region\n",
    "    # X['uncertainty_indicator'] = np.where(\n",
    "    #     (X['loan_intent'] == 'HOMEIMPROVEMENT') & (X['person_age'] < 35) & (X['credit_score'] < 600), #& (X['credit_score'] < 600),\n",
    "    #     1,\n",
    "    #     0\n",
    "    # )\n",
    "    # X['uncertainty_indicator'] = np.where(\n",
    "    #     (X['person_education'] == 'High School'), #& (X['person_gender'] == 'female'),\n",
    "    #     1,\n",
    "    #     0\n",
    "    # )\n",
    "    X['uncertainty_indicator'] = np.where(\n",
    "        (X['loan_int_rate'] < 6), #& (X['credit_score'] < 600),\n",
    "        1,\n",
    "        0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94377963-7370-436c-aced-22e9fe402d45",
   "metadata": {},
   "source": [
    "### Data reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f0a9b-28f5-41b3-96bd-59dfa596b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Exclude 'uncertainty_indicator' from numerical_cols\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col != 'uncertainty_indicator']\n",
    "\n",
    "# Encode target if it's categorical\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1ef8a-922c-4a67-9370-d6398c6e20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets, including the indicator\n",
    "X_train, X_test, y_train, y_test, indicator_train, indicator_test = train_test_split(\n",
    "    X.drop(columns=['uncertainty_indicator']),  # Features excluding the indicator\n",
    "    y,\n",
    "    X['uncertainty_indicator'],  # Indicator\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Reset indices to ensure positional indexing\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "y_test = pd.Series(y_test).reset_index(drop=True)\n",
    "indicator_train = pd.Series(indicator_train).reset_index(drop=True)\n",
    "indicator_test = pd.Series(indicator_test).reset_index(drop=True)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# Encode categorical features\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64391190-13ad-4695-b42b-a24c319ff427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y, indicator, categorical_cols, numerical_cols):\n",
    "        self.X = X.reset_index(drop=True)\n",
    "        self.y = pd.Series(y).reset_index(drop=True)\n",
    "        self.indicator = pd.Series(indicator).reset_index(drop=True)\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.numerical_cols = numerical_cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Categorical features\n",
    "        cat = torch.tensor(self.X.iloc[idx][self.categorical_cols].values, dtype=torch.long)\n",
    "        \n",
    "        # Numerical features\n",
    "        num = torch.tensor(self.X.iloc[idx][self.numerical_cols].values, dtype=torch.float)\n",
    "        \n",
    "        # Target variable (class index: 0 or 1)\n",
    "        target = torch.tensor(self.y.iloc[idx], dtype=torch.long)  # Changed to long\n",
    "        \n",
    "        # Indicator (not used as a feature)\n",
    "        indicator = torch.tensor(self.indicator.iloc[idx], dtype=torch.float)\n",
    "        \n",
    "        return cat, num, target, indicator\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TabularDataset(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    indicator_train,\n",
    "    categorical_cols,\n",
    "    numerical_cols\n",
    ")\n",
    "test_dataset = TabularDataset(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    indicator_test,\n",
    "    categorical_cols,\n",
    "    numerical_cols\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2120b1d-e6b6-4528-8d6b-c7121dd3fb61",
   "metadata": {},
   "source": [
    "### Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d16b8b-2cb5-4db1-9254-d59fce8ff13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embedding_sizes, \n",
    "                 n_cont, \n",
    "                 out_size=2,  # Two classes\n",
    "                 layers=[64, 32], \n",
    "                 p=0.5):\n",
    "        super(TabularModel, self).__init__()\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(categories, size) for categories, size in embedding_sizes\n",
    "        ])\n",
    "        n_emb = sum([size for _, size in embedding_sizes])\n",
    "        self.n_cont = n_cont\n",
    "\n",
    "        self.fc1 = nn.Linear(n_emb + n_cont, layers[0])\n",
    "        self.bn1 = nn.BatchNorm1d(layers[0])\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.bn_layers = nn.ModuleList()\n",
    "        for i in range(len(layers)-1):\n",
    "            self.fc_layers.append(nn.Linear(layers[i], layers[i+1]))\n",
    "            self.bn_layers.append(nn.BatchNorm1d(layers[i+1]))\n",
    "        self.output = nn.Linear(layers[-1], out_size)  # Dual-output\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.embeddings:\n",
    "            x = [emb(x_cat[:,i]) for i, emb in enumerate(self.embeddings)]\n",
    "            x = torch.cat(x, 1)\n",
    "        if self.n_cont > 0:\n",
    "            x = torch.cat([x, x_cont], 1)\n",
    "        x = self.dropout(self.relu(self.bn1(self.fc1(x))))\n",
    "        for fc, bn in zip(self.fc_layers, self.bn_layers):\n",
    "            x = self.dropout(self.relu(bn(fc(x))))\n",
    "        logits = self.output(x)\n",
    "        return logits  # No softmax applied here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44efc565-5875-4568-b77b-a170c2a351a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Embedding Sizes\n",
    "embedding_sizes = []\n",
    "for col in categorical_cols:\n",
    "    num_unique = X_train[col].nunique()\n",
    "    embedding_size = min(50, (num_unique + 1) // 2)\n",
    "    embedding_sizes.append((num_unique, embedding_size))\n",
    "\n",
    "# b. Initialize the Model\n",
    "n_cont = len(numerical_cols)\n",
    "model = TabularModel(embedding_sizes, n_cont, out_size=2, layers=[64, 32], p=0.5)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0dc6d-8f79-43b9-a4cf-2e7d0ad465bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Loss Function and Optimizer\n",
    "# Using CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fa588-628a-4b3d-b5a1-ede2639ecea3",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448a5c1-57ff-40f6-a81f-c3c540507df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Helper Function for Accuracy Calculation\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Computes the accuracy for binary classification.\n",
    "\n",
    "    Args:\n",
    "        preds (Tensor): Predictions after softmax activation, shape (batch_size, 2)\n",
    "        y (Tensor): True labels, shape (batch_size,)\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy as a percentage.\n",
    "    \"\"\"\n",
    "    # Get the predicted class by taking the argmax\n",
    "    _, preds_class = preds.max(1)  # preds_class: (batch_size,)\n",
    "    \n",
    "    # Compare with true labels\n",
    "    correct = (preds_class == y).float()\n",
    "    \n",
    "    # Compute accuracy\n",
    "    acc = correct.sum() / len(correct) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e983b-ccad-47e7-8ab0-ac96795b93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Loop with Accuracy Tracking\n",
    "epochs = args.train_epochs\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_uncertainty = 0  # To track the number of indicators set to 1\n",
    "    \n",
    "    for X_cat, X_cont, y_batch, indicator in train_loader:\n",
    "        # Move data to device\n",
    "        X_cat, X_cont, y_batch = X_cat.to(device), X_cont.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(X_cat, X_cont)  # Shape: (batch_size, 2)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item() * y_batch.size(0)\n",
    "        \n",
    "        # Access the uncertainty_indicator (not used as a feature)\n",
    "        total_uncertainty += indicator.sum().item()\n",
    "        \n",
    "        # Compute accuracy for the batch\n",
    "        preds = torch.softmax(logits, dim=1)  # Apply softmax to get probabilities\n",
    "        acc = binary_accuracy(preds, y_batch)\n",
    "        total_correct += (preds.argmax(1) == y_batch).float().sum().item()\n",
    "        total_samples += y_batch.size(0)\n",
    "    \n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    avg_acc = (total_correct / total_samples) * 100\n",
    "    uncertainty_percentage = (total_uncertainty / len(train_loader.dataset)) * 100\n",
    "    \n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_samples = 0\n",
    "    val_uncertainty = 0\n",
    "    with torch.no_grad():\n",
    "        for X_cat, X_cont, y_batch, indicator in test_loader:\n",
    "            # Move data to device\n",
    "            X_cat, X_cont, y_batch = X_cat.to(device), X_cont.to(device), y_batch.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(X_cat, X_cont)  # Shape: (batch_size, 2)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            \n",
    "            # Accumulate loss\n",
    "            val_loss += loss.item() * y_batch.size(0)\n",
    "            \n",
    "            # Access the uncertainty_indicator in validation\n",
    "            val_uncertainty += indicator.sum().item()\n",
    "            \n",
    "            # Compute accuracy for the batch\n",
    "            preds = torch.softmax(logits, dim=1)\n",
    "            acc = binary_accuracy(preds, y_batch)\n",
    "            val_correct += (preds.argmax(1) == y_batch).float().sum().item()\n",
    "            val_samples += y_batch.size(0)\n",
    "    \n",
    "    # Calculate average validation loss and accuracy\n",
    "    avg_val_loss = val_loss / len(test_loader.dataset)\n",
    "    avg_val_acc = (val_correct / val_samples) * 100\n",
    "    val_uncertainty_percentage = (val_uncertainty / len(test_loader.dataset)) * 100\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}, \"\n",
    "          f\"Training Accuracy: {avg_acc:.2f}%, \"\n",
    "          f\"Training Uncertainty: {uncertainty_percentage:.2f}%, \"\n",
    "          f\"Validation Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Validation Accuracy: {avg_val_acc:.2f}%, \"\n",
    "          f\"Validation Uncertainty: {val_uncertainty_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80de0b-8132-46d8-b296-c58e33b71b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == \"adult\":\n",
    "    torch.save(model.state_dict(), f\"tabnet_adult_base.pth\")\n",
    "else:\n",
    "    torch.save(model.state_dict(), f\"tabnet_credit_base.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aae773-70a3-456f-a662-a46473cc94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved state dictionary\n",
    "if args.dataset == \"adult\":\n",
    "    state_dict = torch.load(f\"tabnet_adult_base.pth\", map_location=device)\n",
    "else:\n",
    "    state_dict = torch.load(f\"tabnet_credit_base.pth\", map_location=device)\n",
    "    \n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d0ffb3-3b10-4b0f-ac7c-2b29679064b2",
   "metadata": {},
   "source": [
    "### Model training with uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf4df6-802f-4c33-b497-9be7c1eb38e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss_fn = nn.CrossEntropyLoss()\n",
    "kl_loss_fn = KLDivLossWithTarget(num_classes=2, epsilon=args.epsilon)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(args.uncert_train_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for X_cat, X_cont, y_batch, indicator in train_loader:\n",
    "        # Move data to device\n",
    "        X_cat, X_cont, y_batch, indicator = X_cat.to(device), X_cont.to(device), y_batch.to(device), indicator.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(X_cat, X_cont)  # Shape: (batch_size, 2)\n",
    "\n",
    "        # Create masks based on the indicator\n",
    "        mask_kl = (indicator == 1)\n",
    "        mask_ce = (indicator == 0)\n",
    "\n",
    "        # Initialize loss\n",
    "        loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "        # Compute KL loss for samples with indicator == 1\n",
    "        if mask_kl.any():\n",
    "            logits_kl = logits[mask_kl]  # Select logits where indicator == 1\n",
    "            y_true_kl = y_batch[mask_kl]  # Select true labels\n",
    "            loss_kl = kl_loss_fn(logits_kl, y_true_kl)\n",
    "            loss += loss_kl\n",
    "\n",
    "        # Compute Cross-Entropy loss for samples with indicator == 0\n",
    "        if mask_ce.any():\n",
    "            logits_ce = logits[mask_ce]  # Select logits where indicator == 0\n",
    "            y_true_ce = y_batch[mask_ce]  # Select true labels\n",
    "            loss_ce = ce_loss_fn(logits_ce, y_true_ce)\n",
    "            loss += loss_ce\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item() * y_batch.size(0)\n",
    "\n",
    "        # Compute accuracy for the batch\n",
    "        preds = logits.argmax(1)  # Predicted classes\n",
    "        total_correct += (preds == y_batch).sum().item()\n",
    "        total_samples += y_batch.size(0)\n",
    "\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    avg_acc = (total_correct / total_samples) * 100\n",
    "\n",
    "    print(avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5c64f-7439-43cf-aa80-8453c26af386",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == \"adult\":\n",
    "    torch.save(model.state_dict(), f\"tabnet_adult_{args.epsilon}.pth\")\n",
    "else:\n",
    "    torch.save(model.state_dict(), f\"tabnet_credit_{args.epsilon}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35678d4-004e-4bb4-9f5c-4957f91f3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == \"adult\":\n",
    "    state_dict = torch.load(f\"tabnet_adult_{args.epsilon}.pth\", map_location=device)\n",
    "else:\n",
    "    state_dict = torch.load(f\"tabnet_credit_{args.epsilon}.pth\", map_location=device)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0c3ad4-68a5-463b-a2db-64526d3ba6b6",
   "metadata": {},
   "source": [
    "### Uncertainty evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ae23b-1ab7-44c7-bafc-6ea55fa7025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "maxconfs = []\n",
    "inds = []\n",
    "corrs = []\n",
    "with torch.no_grad():\n",
    "    for X_cat, X_cont, y_batch, indicator in test_loader:\n",
    "        X_cat, X_cont = X_cat.to(device), X_cont.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        logits = model(X_cat, X_cont)  # Shape: (batch_size, 2)\n",
    "        probs = torch.softmax(logits, dim=1)  # Apply softmax\n",
    "        confs, preds = probs.max(1)  # Predicted classes\n",
    "        maxconfs.extend(confs.cpu().numpy())\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        actuals.extend(y_batch.cpu().numpy())\n",
    "        inds.extend(indicator.cpu().numpy().astype(int))\n",
    "        corrs.extend(preds.eq(y_batch).cpu().numpy())\n",
    "\n",
    "maxconfs = np.array(maxconfs)\n",
    "inds = np.array(inds)\n",
    "corrs = np.array(corrs)\n",
    "correctness_indic = (torch.tensor(predictions) == torch.tensor(actuals)).float()[inds == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edac477-7582-4ff5-8e4e-0e55b5017e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reliability_diagram(confidences, correctness, num_bins=10):\n",
    "    \"\"\"\n",
    "    Computes the reliability diagram metrics.\n",
    "\n",
    "    Args:\n",
    "        confidences (np.array): Array of predicted confidence scores.\n",
    "        correctness (np.array): Array of binary correctness indicators.\n",
    "        num_bins (int): Number of bins to divide the confidence scores.\n",
    "\n",
    "    Returns:\n",
    "        bin_centers (np.array): Centers of the confidence bins.\n",
    "        bin_accuracy (np.array): Accuracy per confidence bin.\n",
    "        bin_confidence (np.array): Average confidence per bin.\n",
    "        bin_counts (np.array): Number of samples per bin.\n",
    "    \"\"\"\n",
    "    bins = np.linspace(0.0, 1.0, num_bins + 1)\n",
    "    bin_indices = np.digitize(confidences, bins, right=True) - 1  # Bin indices start at 0\n",
    "    bin_indices = np.clip(bin_indices, 0, num_bins - 1)  # Handle edge cases\n",
    "    \n",
    "    bin_accuracy = np.zeros(num_bins)\n",
    "    bin_confidence = np.zeros(num_bins)\n",
    "    bin_counts = np.zeros(num_bins)\n",
    "    \n",
    "    for b in range(num_bins):\n",
    "        in_bin = bin_indices == b\n",
    "        bin_counts[b] = np.sum(in_bin)\n",
    "        if bin_counts[b] > 0:\n",
    "            bin_accuracy[b] = np.mean(correctness[in_bin])\n",
    "            bin_confidence[b] = np.mean(confidences[in_bin])\n",
    "        else:\n",
    "            bin_accuracy[b] = np.nan\n",
    "            bin_confidence[b] = np.nan\n",
    "    \n",
    "    # Compute bin centers for plotting\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2.0\n",
    "    \n",
    "    return bin_centers, bin_accuracy, bin_confidence, bin_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7002c278-1df1-44a5-a88b-eef0ac52829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 2.25))\n",
    "\n",
    "sns.kdeplot(maxconfs[inds == 0], color='tab:blue', label=\"Other\", fill=True, ax=axs[0], lw=2)\n",
    "sns.kdeplot(maxconfs[inds == 1], color='tab:red', label=\"Uncert\", fill=True, ax=axs[0], lw=2)\n",
    "axs[0].set_xlim(0.4,1)\n",
    "axs[0].set_xlabel(\"Confidence\")\n",
    "axs[0].set_ylabel('Adult\\nDensity')\n",
    "axs[0].axvline(0.5, color=\"black\", linestyle=\"--\", label=r\"$\\frac{1}{C}$\")\n",
    "axs[0].axvline(0.5 + args.epsilon, color=\"black\", linestyle=\":\", label=r\"$\\frac{1}{C} + \\epsilon$\")\n",
    "\n",
    "axs[0].set_title(\"Confidence Distributions\")\n",
    "axs[0].legend(loc=\"upper left\")\n",
    "\n",
    "bin_centers, bin_accuracy, bin_confidence, bin_counts = reliability_diagram(\n",
    "    maxconfs,\n",
    "    corrs,\n",
    "    num_bins=20\n",
    ")\n",
    "\n",
    "axs[1].plot([0, 1], [0, 1], color='lightgray', lw=2, label='Perf cal')\n",
    "axs[1].plot(bin_confidence, bin_accuracy, marker='o', label='Cal', lw=2)\n",
    "\n",
    "axs[1].axvline(0.5, color=\"black\", linestyle=\"--\")\n",
    "axs[1].axvline(0.5 + args.epsilon, color=\"black\", linestyle=\":\")\n",
    "axs[1].legend(loc=\"lower right\")\n",
    "axs[1].set_title(\"Reliability Diagram\")\n",
    "\n",
    "axs[1].set_xlabel('Confidence')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_xlim(0.4,1.02)\n",
    "axs[1].set_ylim(0.4,1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/credit_res_intrate.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe521cb-f73c-4654-997b-d3b6300ba1db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
